{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from fpdf import FPDF\n",
        "from datetime import datetime\n",
        "\n",
        "fear_file = \"/content/fear_greed_index.csv\"\n",
        "hist_file = \"/content/historical_data.csv\"\n",
        "out_dir = \"./outputs\"\n",
        "csv_out_dir = \"./csv_files\"\n",
        "pdf_path = os.path.join(out_dir, \"ds_report.pdf\")\n",
        "\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "os.makedirs(csv_out_dir, exist_ok=True)\n",
        "\n",
        "def norm_cols(df):\n",
        "    df.columns = [str(c).strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\").replace(\".\", \"_\") for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def find_col_by_candidates(cols, candidates):\n",
        "    cols = [c.lower() for c in cols]\n",
        "    for cand in candidates:\n",
        "        if cand in cols:\n",
        "            return [c for c in cols if c==cand][0]\n",
        "    for cand in candidates:\n",
        "        for c in cols:\n",
        "            if cand in c:\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "fg = pd.read_csv(fear_file)\n",
        "hist = pd.read_csv(hist_file)\n",
        "print(\"Loaded FG:\", fg.shape, \"HIST:\", hist.shape)\n",
        "\n",
        "fg = norm_cols(fg)\n",
        "hist = norm_cols(hist)\n",
        "\n",
        "fg_date_col = find_col_by_candidates(fg.columns, [\"date\",\"timestamp\",\"time\",\"day\"])\n",
        "hist_date_col = find_col_by_candidates(hist.columns, [\"timestamp\",\"time\",\"date\",\"trade_time\",\"ts\"])\n",
        "\n",
        "if fg_date_col is None or hist_date_col is None:\n",
        "    raise ValueError(\"Could not find date/time columns.\")\n",
        "\n",
        "fg[fg_date_col] = pd.to_datetime(fg[fg_date_col], errors=\"coerce\", infer_datetime_format=True)\n",
        "hist[hist_date_col] = pd.to_datetime(hist[hist_date_col], errors=\"coerce\", infer_datetime_format=True)\n",
        "\n",
        "sent_col = find_col_by_candidates(fg.columns, [\"classification\", \"sentiment\", \"label\", \"fear_greed\"])\n",
        "if sent_col is None:\n",
        "    for c in fg.columns:\n",
        "        vals = fg[c].dropna().astype(str).str.lower().unique()[:10]\n",
        "        if any(v in [\"fear\", \"greed\"] for v in vals):\n",
        "            sent_col = c\n",
        "            break\n",
        "if sent_col is None:\n",
        "    raise ValueError(\"Could not detect sentiment/classification column.\")\n",
        "\n",
        "fg = fg.rename(columns={fg_date_col: \"date\", sent_col: \"classification\"})\n",
        "fg[\"classification\"] = fg[\"classification\"].astype(str).str.strip().str.capitalize()\n",
        "fg = fg[fg[\"classification\"].isin([\"Fear\", \"Greed\"])].copy()\n",
        "print(\"FG sentiment counts:\\n\", fg[\"classification\"].value_counts())\n",
        "\n",
        "mappings = {\n",
        "    \"account\": [\"account\",\"acct\",\"user\",\"trader\"],\n",
        "    \"symbol\": [\"symbol\",\"pair\",\"ticker\",\"coin\"],\n",
        "    \"execution_price\": [\"execution_price\",\"price\",\"executionprice\",\"exec_price\",\"px\"],\n",
        "    \"size\": [\"size\",\"qty\",\"quantity\",\"order_size\",\"size_tokens\",\"size_usd\"],\n",
        "    \"side\": [\"side\",\"direction\",\"buy_sell\",\"action\"],\n",
        "    \"closedpnl\": [\"closedpnl\",\"closed_pnl\",\"pnl\",\"realized_pnl\"],\n",
        "    \"leverage\": [\"leverage\",\"lev\",\"leverage_x\"],\n",
        "    \"order_id\": [\"order_id\", \"orderid\"]\n",
        "}\n",
        "found = {}\n",
        "for target, candidates in mappings.items():\n",
        "    col = find_col_by_candidates(hist.columns, candidates)\n",
        "    if col:\n",
        "        found[col] = target\n",
        "\n",
        "hist = hist.rename(columns=found)\n",
        "print(\"Detected / renamed columns:\", found)\n",
        "\n",
        "for col in [\"execution_price\", \"size\", \"closedpnl\", \"leverage\"]:\n",
        "    if col in hist.columns:\n",
        "        hist[col] = pd.to_numeric(hist[col], errors=\"coerce\")\n",
        "\n",
        "if hist_date_col != \"date\":\n",
        "    hist = hist.rename(columns={hist_date_col: \"date\"})\n",
        "\n",
        "fg[\"date_only\"] = fg[\"date\"].dt.normalize()\n",
        "hist[\"date_only\"] = hist[\"date\"].dt.normalize()\n",
        "fg = fg.dropna(subset=[\"date_only\"])\n",
        "hist = hist.dropna(subset=[\"date_only\"])\n",
        "\n",
        "hist = hist.sort_values(\"date_only\")\n",
        "fg = fg.sort_values(\"date_only\")\n",
        "\n",
        "merged = pd.merge_asof(\n",
        "    hist,\n",
        "    fg[[\"date_only\", \"classification\"]],\n",
        "    on=\"date_only\",\n",
        "    direction=\"nearest\"\n",
        ")\n",
        "print(\"Merged dataset shape:\", merged.shape, \"Missing sentiments:\", merged[\"classification\"].isna().sum())\n",
        "\n",
        "if \"size\" in merged.columns and \"closedpnl\" in merged.columns:\n",
        "    merged[\"profit_margin\"] = np.where(merged[\"size\"].notna() & merged[\"closedpnl\"].notna(), merged[\"closedpnl\"] / merged[\"size\"], np.nan)\n",
        "if \"size\" in merged.columns and \"leverage\" in merged.columns:\n",
        "    merged[\"risk\"] = np.where(merged[\"size\"].notna() & merged[\"leverage\"].notna(), merged[\"size\"] * merged[\"leverage\"], np.nan)\n",
        "merged[\"sentiment_numeric\"] = merged[\"classification\"].map({\"Fear\":0,\"Greed\":1})\n",
        "\n",
        "agg_dict = {\"trades_count\": (\"account\",\"count\")}\n",
        "if \"closedpnl\" in merged.columns:\n",
        "    agg_dict.update({\"avg_closedpnl\": (\"closedpnl\",\"mean\"), \"median_closedpnl\": (\"closedpnl\",\"median\")})\n",
        "if \"leverage\" in merged.columns:\n",
        "    agg_dict.update({\"avg_leverage\": (\"leverage\",\"mean\")})\n",
        "if \"size\" in merged.columns:\n",
        "    agg_dict.update({\"median_size\": (\"size\",\"median\")})\n",
        "if \"profit_margin\" in merged.columns:\n",
        "    agg_dict.update({\"avg_profit_margin\": (\"profit_margin\",\"mean\")})\n",
        "\n",
        "agg_by_sent = merged.groupby(\"classification\").agg(**agg_dict).reset_index()\n",
        "print(\"Aggregations:\\n\", agg_by_sent)\n",
        "\n",
        "csv_path = os.path.join(csv_out_dir, \"processed_data.csv\")\n",
        "merged.to_csv(csv_path, index=False)\n",
        "\n",
        "plots = []\n",
        "if \"closedpnl\" in merged.columns and merged[\"classification\"].notna().any():\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    data_fear = merged[merged[\"classification\"] == \"Fear\"][\"closedpnl\"].dropna()\n",
        "    data_greed = merged[merged[\"classification\"] == \"Greed\"][\"closedpnl\"].dropna()\n",
        "    ax.boxplot([data_fear, data_greed], labels=[\"Fear\", \"Greed\"])\n",
        "    ax.set_title(\"Closed PnL by Sentiment\")\n",
        "    ax.set_ylabel(\"Closed PnL\")\n",
        "    p1 = os.path.join(out_dir, \"boxplot_closedpnl_by_sentiment.png\")\n",
        "    fig.savefig(p1, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    plots.append(p1)\n",
        "\n",
        "if \"leverage\" in merged.columns:\n",
        "    for sent in [\"Fear\", \"Greed\"]:\n",
        "        vals = merged.loc[merged[\"classification\"] == sent, \"leverage\"].dropna()\n",
        "        if len(vals) > 0:\n",
        "            fig, ax = plt.subplots(figsize=(6, 4))\n",
        "            ax.hist(vals, bins=30)\n",
        "            ax.set_title(f\"Leverage distribution - {sent}\")\n",
        "            ax.set_xlabel(\"Leverage\")\n",
        "            ax.set_ylabel(\"Count\")\n",
        "            p = os.path.join(out_dir, f\"hist_leverage_{sent.lower()}.png\")\n",
        "            fig.savefig(p, bbox_inches=\"tight\")\n",
        "            plt.close(fig)\n",
        "            plots.append(p)\n",
        "\n",
        "if \"size\" in merged.columns and \"closedpnl\" in merged.columns and \"sentiment_numeric\" in merged.columns:\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    scatter = ax.scatter(merged[\"size\"], merged[\"closedpnl\"], c=merged[\"sentiment_numeric\"], cmap='viridis', alpha=0.6)\n",
        "    ax.set_title(\"Closed PnL vs Trade Size (by Sentiment)\")\n",
        "    ax.set_xlabel(\"Trade Size\")\n",
        "    ax.set_ylabel(\"Closed PnL\")\n",
        "\n",
        "    legend1 = ax.legend(handles=scatter.legend_elements()[0], labels=[\"Fear\", \"Greed\"], title=\"Sentiment\")\n",
        "    ax.add_artist(legend1)\n",
        "\n",
        "    p_new = os.path.join(out_dir, \"scatter_pnl_vs_size_by_sentiment.png\")\n",
        "    fig.savefig(p_new, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    plots.append(p_new)\n",
        "\n",
        "\n",
        "numcols = merged.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if len(numcols) >= 2:\n",
        "    corr = merged[numcols].corr()\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    cax = ax.matshow(corr, cmap=\"coolwarm\")\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_xticks(range(len(numcols)))\n",
        "    ax.set_yticks(range(len(numcols)))\n",
        "    ax.set_xticklabels(numcols, rotation=90)\n",
        "    ax.set_yticklabels(numcols)\n",
        "    ax.set_title(\"Correlation Matrix\")\n",
        "    p = os.path.join(out_dir, \"corr_matrix.png\")\n",
        "    fig.savefig(p, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    plots.append(p)\n",
        "\n",
        "print(\"Saved plots:\", plots)\n",
        "\n",
        "pdf = FPDF()\n",
        "pdf.set_auto_page_break(auto=True, margin=15)\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Arial\", size=12)\n",
        "pdf.cell(0, 8, \"Data Science Assignment - Trader Behavior vs Market Sentiment\", ln=True)\n",
        "pdf.ln(4)\n",
        "pdf.set_font(\"Arial\", size=10)\n",
        "pdf.multi_cell(0, 6, \"This report contains automatic aggregates and saved visualizations from the processed datasets. See images appended.\")\n",
        "\n",
        "pdf.ln(4)\n",
        "pdf.set_font(\"Arial\", size=9)\n",
        "if not agg_by_sent.empty:\n",
        "    for _, row in agg_by_sent.iterrows():\n",
        "        avg_closedpnl_val = row.get('avg_closedpnl', 'NA')\n",
        "        avg_leverage_val = row.get('avg_leverage', 'NA')\n",
        "\n",
        "        avg_closedpnl_str = f\"{avg_closedpnl_val:.4f}\" if isinstance(avg_closedpnl_val, (int, float)) else avg_closedpnl_val\n",
        "        avg_leverage_str = f\"{avg_leverage_val:.3f}\" if isinstance(avg_leverage_val, (int, float)) else avg_leverage_val\n",
        "\n",
        "        pdf.multi_cell(0, 6, f\"{row['classification']}: trades={int(row['trades_count'])}, avg_closedpnl={avg_closedpnl_str}, avg_leverage={avg_leverage_str}\")\n",
        "\n",
        "for p in plots:\n",
        "    try:\n",
        "        pdf.add_page()\n",
        "        pdf.image(p, x=10, y=25, w=190)\n",
        "    except Exception as e:\n",
        "        print(\"Warning: could not add image to PDF:\", p, e)\n",
        "\n",
        "pdf.output(pdf_path)\n",
        "print(\"Saved PDF:\", pdf_path)\n",
        "\n",
        "print(\"Done. Files created:\")\n",
        "print(\"Processed CSV:\", csv_path)\n",
        "print(\"Outputs directory:\", out_dir)\n",
        "print(\"PDF report:\", pdf_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6LXRxAaxPvR",
        "outputId": "03d1633c-3af9-46c8-89d9-5aa52519629c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded FG: (2644, 4) HIST: (211224, 16)\n",
            "FG sentiment counts:\n",
            " classification\n",
            "Fear     781\n",
            "Greed    633\n",
            "Name: count, dtype: int64\n",
            "Detected / renamed columns: {'account': 'account', 'coin': 'symbol', 'execution_price': 'execution_price', 'size_tokens': 'size', 'side': 'side', 'closed_pnl': 'closedpnl', 'order_id': 'order_id'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2171860967.py:51: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  fg[fg_date_col] = pd.to_datetime(fg[fg_date_col], errors=\"coerce\", infer_datetime_format=True)\n",
            "/tmp/ipython-input-2171860967.py:52: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  hist[hist_date_col] = pd.to_datetime(hist[hist_date_col], errors=\"coerce\", infer_datetime_format=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged dataset shape: (211224, 18) Missing sentiments: 0\n",
            "Aggregations:\n",
            "   classification  trades_count  avg_closedpnl  median_closedpnl  median_size  \\\n",
            "0           Fear        211224      48.749001               0.0         32.0   \n",
            "\n",
            "   avg_profit_margin  \n",
            "0           18.30723  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2171860967.py:148: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  ax.boxplot([data_fear, data_greed], labels=[\"Fear\", \"Greed\"])\n",
            "/tmp/ipython-input-2171860967.py:178: UserWarning: Mismatched number of handles and labels: len(handles) = 1 len(labels) = 2\n",
            "  legend1 = ax.legend(handles=scatter.legend_elements()[0], labels=[\"Fear\", \"Greed\"], title=\"Sentiment\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plots: ['./outputs/boxplot_closedpnl_by_sentiment.png', './outputs/scatter_pnl_vs_size_by_sentiment.png', './outputs/corr_matrix.png']\n",
            "Saved PDF: ./outputs/ds_report.pdf\n",
            "Done. Files created:\n",
            "Processed CSV: ./csv_files/processed_data.csv\n",
            "Outputs directory: ./outputs\n",
            "PDF report: ./outputs/ds_report.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V18fYpgj0ZgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}